{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ML Seminar 5\n",
    "\n",
    "Grid Search and beyond in sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The usual goal reminder\n",
    "<center>\n",
    "Build a [wine quality](https://archive.ics.uci.edu/ml/datasets/wine+quality) detector!\n",
    "\n",
    "<img src=\"misc/wine.svg\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "We are going to finish this today.\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cross - validation\n",
    "\n",
    "Next step for the validation dataset:\n",
    "\n",
    "All data is split into folds, and every fold is successively used as validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.384060958672\n",
      "0.374563753236\n"
     ]
    }
   ],
   "source": [
    "import pandas as ps\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# read the file as csv\n",
    "Xy = ps.read_csv('data/winequality-red.csv', sep=';').as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xy[:, :-1], Xy[:, -1], random_state=0)\n",
    "\n",
    "# create a model class instance\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR(),\n",
    ")\n",
    "\n",
    "# setting parameters in the pipeline\n",
    "model.set_params(\n",
    "    standardscaler__with_std=True,\n",
    "    svr__C=1.0,\n",
    ")\n",
    "\n",
    "# get the cross - validation score estimate\n",
    "sc = cross_val_score(model, X_train, y_train, cv=4)\n",
    "print(sum(sc) / 4.0)\n",
    "\n",
    "# fit a model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model on the data\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grid Search\n",
    "\n",
    "Search automatically for the good values of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n",
      "0.374776767158\n",
      "Example estimations\n",
      "[(6.0, 5.119298583703296), (5.0, 5.1679546993499574), (7.0, 7.0942408979956673), (6.0, 4.8421969242225433), (5.0, 6.0050072789140199), (6.0, 5.2082930080415828), (5.0, 5.0528333146304885), (6.0, 5.9496966127585198), (4.0, 5.0921054035949931), (5.0, 5.0883908910564859)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  54 out of  54 | elapsed:    1.0s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as ps\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# read the file as csv\n",
    "Xy = ps.read_csv('data/winequality-red.csv', sep=';').as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xy[:, :-1], Xy[:, -1], random_state=0)\n",
    "\n",
    "# create a model class instance\n",
    "estimator = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR(),\n",
    ")\n",
    "\n",
    "# create an instance of a grid search class\n",
    "model = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid={\n",
    "        \"standardscaler__with_std\": [True, False],\n",
    "        \"svr__C\": [0.1, 1.0, 10.0],\n",
    "        \"svr__gamma\": [0.1, 1.0, 10.0],\n",
    "    },\n",
    "    verbose=1,\n",
    "    n_jobs=8,\n",
    ")\n",
    "\n",
    "# fit a model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model on the data\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# make estimations as usual\n",
    "yp = model.predict(X_test)\n",
    "\n",
    "print(\"Example estimations\")\n",
    "print([v for v in zip(y_test[:10], yp[:10])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Try more than one class of models\n",
    "\n",
    "* Explore linear and kNN model in `MLSeminar2_2.pdf`\n",
    "\n",
    "* Use these two classes in GridSearchCV\n",
    "\n",
    "*Note*: See example parameter ranges for models and their \"comparison\" here:\n",
    "https://arxiv.org/pdf/1708.05070.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "{'model': Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000,\n",
      "   normalize=False, positive=False, precompute=False, random_state=None,\n",
      "   selection='cyclic', tol=0.0001, warm_start=False), 'model__alpha': 0.01}\n",
      "0.338515504834656\n",
      "Example estimations\n",
      "[(6.0, 5.7686006218926025), (5.0, 5.034163979580779), (7.0, 6.5095248248564), (6.0, 5.38237161642421), (5.0, 5.8686735982789715), (6.0, 5.101823625659236), (5.0, 5.37781568807379), (6.0, 5.972112277618752), (4.0, 4.836185272129585), (5.0, 5.008708344116504)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   3 out of  18 | elapsed:    0.0s remaining:    0.1s\n",
      "[Parallel(n_jobs=8)]: Done  18 out of  18 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as ps\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# read the file as csv\n",
    "Xy = ps.read_csv('data/winequality-red.csv', sep=';').as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xy[:, :-1], Xy[:, -1], random_state=0)\n",
    "\n",
    "# create a model class instance\n",
    "estimator = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Lasso()),\n",
    "])\n",
    "\n",
    "# create an instance of a grid search class\n",
    "model = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=[ # a list of dicts - understood as a list of subspaces to look into\n",
    "        {\n",
    "            \"model\":[KNeighborsRegressor()], # fix the model like this\n",
    "            \"model__n_neighbors\": [1, 2, 3], # set parameters of the pipeline\n",
    "            'model__metric': ['minkowski']\n",
    "        },\n",
    "        {\n",
    "            \"model\":[Lasso()],\n",
    "            \"model__alpha\": [0.01, 0.1, 1.0]\n",
    "        }\n",
    "    ],\n",
    "    verbose=1,\n",
    "    n_jobs=8,\n",
    ")\n",
    "\n",
    "\n",
    "# fit a model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(model.best_params_)\n",
    "\n",
    "# evaluate the model on the data\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# make estimations as usual\n",
    "yp = model.predict(X_test)\n",
    "\n",
    "print(\"Example estimations\")\n",
    "print([v for v in zip(y_test[:10], yp[:10])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making your own transformer or estimator\n",
    "\n",
    "* Often useful for dedicated feature extraction\n",
    "\n",
    "* Will be useful soon for data preprocessing\n",
    "\n",
    "Example is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  12 out of  27 | elapsed:    0.2s remaining:    0.3s\n",
      "[Parallel(n_jobs=8)]: Done  27 out of  27 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.374776767158\n",
      "Example estimations\n",
      "[(6.0, 5.1192985837032978), (5.0, 5.1679546993499654), (7.0, 7.0942408979956681), (6.0, 4.8421969242225291), (5.0, 6.0050072789140261), (6.0, 5.2082930080415846), (5.0, 5.0528333146304876), (6.0, 5.9496966127585189), (4.0, 5.0921054035949984), (5.0, 5.0883908910564912)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as ps\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "# some of already available functionality\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "# read the file as csv\n",
    "Xy = ps.read_csv('data/winequality-red.csv', sep=';').as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xy[:, :-1], Xy[:, -1], random_state=0)\n",
    "\n",
    "class MedianScaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Subtract the median of column values from every column\n",
    "    of the dataset matrix, and divide every column by \n",
    "    the median of absolute deviation from median.\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    \n",
    "    median_: numpy nd array of shape (n_features,)\n",
    "        contains median of values\n",
    "    \n",
    "    absdev_: ...        \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.median_ = None\n",
    "        self.std_ = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Fits the scaler to the data. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        X: array like of shape [n_samples, ...].\n",
    "            Dataset        \n",
    "        \"\"\"\n",
    "        self.median_ = np.median(X, axis=0)\n",
    "        X = X - self.median_\n",
    "        self.std_ = np.std(X, axis=0)\n",
    "        \n",
    "        # !!! important\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"\n",
    "        ...enter the description here!\n",
    "        \"\"\"\n",
    "        X = X - self.median_\n",
    "        X = X / self.std_\n",
    "        return X    \n",
    "    \n",
    "# create a model class instance\n",
    "estimator = make_pipeline(\n",
    "    MedianScaler(),\n",
    "    SVR(),\n",
    ")\n",
    "\n",
    "# create an instance of a grid search class\n",
    "model = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid={\n",
    "        \"svr__C\": [0.1, 1.0, 10.0],\n",
    "        \"svr__gamma\": [0.1, 1.0, 10.0],\n",
    "    },\n",
    "    verbose=1,\n",
    "    n_jobs=8,\n",
    ")\n",
    "\n",
    "# fit a model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model on the data\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# make estimations as usual\n",
    "yp = model.predict(X_test)\n",
    "\n",
    "print(\"Example estimations\")\n",
    "print([v for v in zip(y_test[:10], yp[:10])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Automated feature processing\n",
    "\n",
    "* Select categorical column\n",
    "\n",
    "* Transform it into numerical columns\n",
    "\n",
    "<center>\n",
    "<img src=\"misc/onehot.svg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Credit approval dataset\n",
    "<center>\n",
    "Build a [credit approval](http://archive.ics.uci.edu/ml/datasets/Credit+Approval) classifier!\n",
    "\n",
    "<img src=\"misc/credit.svg\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "Requires some data preprocessing!\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['58.67' 0 1 0 0]\n",
      " ['24.50' 0 1 0 0]\n",
      " ['27.83' 0 1 0 0]\n",
      " ..., \n",
      " ['25.25' 0 0 0 1]\n",
      " ['17.92' 0 1 0 0]\n",
      " ['35.00' 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as ps\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_union, make_pipeline\n",
    "\n",
    "# class that selects a single column\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, [self.index]]\n",
    "\n",
    "# class that encodes the column \n",
    "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.model = LabelBinarizer()\n",
    "        self.model.fit(X[:, 0])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.model.transform(X[:, 0])\n",
    "        \n",
    "    \n",
    "# read the file as csv\n",
    "Xy = ps.read_csv('data/credit-screening.csv').as_matrix()\n",
    "X = Xy\n",
    "\n",
    "cs = ColumnSelector(0)\n",
    "X = cs.fit_transform(X)\n",
    "hot = OneHotEncoder();\n",
    "X = hot.fit_transform(X)\n",
    "#print(X)\n",
    "\n",
    "# this joins multiple extracted features into one dataset\n",
    "features = make_union(\n",
    "    ColumnSelector(1),\n",
    "    make_pipeline(ColumnSelector(4), OneHotEncoder())\n",
    ")\n",
    "\n",
    "print(features.fit_transform(Xy))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
