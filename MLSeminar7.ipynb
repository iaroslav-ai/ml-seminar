{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ML Seminar 7\n",
    "\n",
    "Data Preprocessing, Bayesian Optimization for ML and beyond"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Credit approval dataset\n",
    "<center>\n",
    "Build a [credit approval](http://archive.ics.uci.edu/ml/datasets/Credit+Approval) classifier!\n",
    "\n",
    "<img src=\"misc/credit.svg\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "Requires some data preprocessing!\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Making data preprocessing a pipeline\n",
    "\n",
    "* Compact code\n",
    "\n",
    "* Reusable in other projects\n",
    "\n",
    "* Adjust pipeline using `GridSearchCV` or the like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]\n",
      " ..., \n",
      " [0 0 0 1]\n",
      " [0 1 0 0]\n",
      " [0 1 0 0]]\n",
      "[['58.67' 0 1 0 0]\n",
      " ['24.50' 0 1 0 0]\n",
      " ['27.83' 0 1 0 0]\n",
      " ..., \n",
      " ['25.25' 0 0 0 1]\n",
      " ['17.92' 0 1 0 0]\n",
      " ['35.00' 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as ps\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_union, make_pipeline\n",
    "\n",
    "# class that selects a single column\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, [self.index]]\n",
    "\n",
    "# class that encodes the column \n",
    "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.model = LabelBinarizer()\n",
    "        self.model.fit(X[:, 0])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.model.transform(X[:, 0])\n",
    "        \n",
    "    \n",
    "# read the file as csv\n",
    "Xy = ps.read_csv('data/credit-screening.csv').as_matrix()\n",
    "X = Xy\n",
    "\n",
    "cs = ColumnSelector(4)\n",
    "X = cs.fit_transform(X)\n",
    "hot = OneHotEncoder();\n",
    "X = hot.fit_transform(X)\n",
    "print(X)\n",
    "\n",
    "# this joins multiple extracted features into one feature set\n",
    "features = make_union(\n",
    "    ColumnSelector(1),\n",
    "    make_pipeline(ColumnSelector(4), OneHotEncoder())\n",
    ")\n",
    "\n",
    "print(features.fit_transform(Xy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A general pipeline\n",
    "\n",
    "Represent data preprocessing, data scaling and model fitting as a single pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of  18 | elapsed:    0.2s remaining:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'est__C': 1.0, 'est': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.1, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False), 'est__gamma': 0.1}\n",
      "0.7976878612716763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "import pandas as ps\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "\n",
    "# class that selects a single column\n",
    "class ColumnSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, index):\n",
    "        self.index = index\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, [self.index]]\n",
    "\n",
    "\n",
    "# class that encodes the column\n",
    "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.model = LabelBinarizer()\n",
    "        self.model.fit(X[:, 0])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.model.transform(X[:, 0])\n",
    "\n",
    "# read the csv file\n",
    "data = ps.read_csv('data/credit-screening.csv', header=None)\n",
    "# replace ? with NaN\n",
    "data = data.replace('?', 'NaN')\n",
    "data = data.as_matrix()\n",
    "\n",
    "# split data \n",
    "X, y = data[:, :-1], data[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# helper functions\n",
    "category = lambda idx: make_pipeline(ColumnSelector(idx), OneHotEncoder())\n",
    "number = lambda idx: make_pipeline(ColumnSelector(idx), Imputer())\n",
    "\n",
    "# feature extraction pipeline\n",
    "features = make_union(\n",
    "    category(0),\n",
    "    number(1),\n",
    "    number(2),\n",
    "    category(3),\n",
    "    category(4),\n",
    "    category(5),\n",
    "    category(6),\n",
    "    number(7),\n",
    "    category(8),\n",
    "    category(9),\n",
    "    number(10),\n",
    "    category(11),\n",
    "    category(12),\n",
    "    number(13),\n",
    "    number(14)\n",
    ")\n",
    "\n",
    "# estimator pipeline\n",
    "model = Pipeline([\n",
    "    ('features', features),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('est', SVC())\n",
    "])\n",
    "\n",
    "# model paramter grid definition\n",
    "svc_grid = {\n",
    "    'est': [SVC()],\n",
    "    'est__C': [0.1, 1.0, 10.0],\n",
    "    'est__gamma': [0.1, 1.0],\n",
    "}\n",
    "\n",
    "# grid search class\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=[svc_grid],\n",
    "    verbose=1,\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# fit all the transformers and estimators in the pipeline\n",
    "gsearch.fit(X_train, y_train)\n",
    "print(gsearch.best_params_)\n",
    "print(gsearch.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Acessing the quality of classification model\n",
    "\n",
    "Is 75% accuracy a good value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Use `DummyClassifier` for comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A general pipeline\n",
    "\n",
    "The code is already quite general and can be fairly easily adjusted to other datasets. \n",
    "\n",
    "*Task* Adjust the pipeline to the `titanic.csv` in `data` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Brute force through high dimensions\n",
    "\n",
    "Using [https://github.com/scikit-optimize/scikit-optimize](https://github.com/scikit-optimize/scikit-optimize)!\n",
    "\n",
    "An idea of how this works is [shown here](https://github.com/scikit-optimize/scikit-optimize/blob/master/examples/bayesian-optimization.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   9 out of  24 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  24 out of  24 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   9 out of  24 | elapsed:    0.2s remaining:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  24 out of  24 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   9 out of  24 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  24 out of  24 | elapsed:    2.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   9 out of  24 | elapsed:    0.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=8)]: Done  24 out of  24 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   9 out of  24 | elapsed:    0.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  24 out of  24 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   9 out of  24 | elapsed:    0.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=8)]: Done  24 out of  24 | elapsed:    0.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done   6 out of   6 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.376378052406\n",
      "Example estimations\n",
      "[(6.0, 5.2458061678985075), (5.0, 5.1795120012465548), (7.0, 7.089794322406445), (6.0, 4.8243386318352313), (5.0, 5.9433703014307051), (6.0, 5.1525783339156055), (5.0, 5.1025421328279013), (6.0, 5.9003136717746401), (4.0, 4.9975256227072622), (5.0, 5.054024756726526)]\n"
     ]
    }
   ],
   "source": [
    "import pandas as ps\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Import necessary functionality from scikit-optimize!\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# read the file as csv\n",
    "Xy = ps.read_csv('data/winequality-red.csv', sep=';').as_matrix()\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xy[:, :-1], Xy[:, -1], random_state=0)\n",
    "    \n",
    "# create a model class instance\n",
    "estimator = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SVR(),\n",
    ")\n",
    "\n",
    "# Bayesian optimization class, which can be used instead of GridSearchCV\n",
    "model = BayesSearchCV(\n",
    "    estimator=estimator,\n",
    "    search_spaces={\n",
    "        \"svr__C\": Real(1e-6, 1e+3, 'log-uniform'),\n",
    "        \"svr__gamma\": Real(1e-3, 1e+3, 'log-uniform'),\n",
    "        \"svr__kernel\": Categorical(['rbf']),\n",
    "        \"svr__degree\": Integer(1, 2),\n",
    "    },\n",
    "    verbose=1,\n",
    "    n_jobs=8,\n",
    ")\n",
    "\n",
    "# fit a model to the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# evaluate the model on the data\n",
    "print(model.score(X_test, y_test))\n",
    "\n",
    "# make estimations as usual\n",
    "yp = model.predict(X_test)\n",
    "\n",
    "print(\"Example estimations\")\n",
    "print([v for v in zip(y_test[:10], yp[:10])])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
